{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activity 17 Perceptrons and Neural Nets - My Method.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzDbWPK3R23i",
        "colab_type": "text"
      },
      "source": [
        "#**Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9tIClVRSAoz",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we'll create a 2-layer nueral network (i.e. a single hidden and output layer) and train it on the XOR data.\n",
        "\n",
        "First, let's import NumPy, our layers and helper functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ41cFKlLPFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import warnings as warn\n",
        "import skimage.measure as meas\n",
        "from numpy import linalg as la, random as rand\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_6W7P1ZS0Z2",
        "colab_type": "code",
        "outputId": "1b9f986c-6121-408f-d79d-f395bf7169e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "X = rand.uniform(-1, 1, 50)\n",
        "X = np.sort(X)\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.90003429, -0.89672046, -0.86033069, -0.84684137, -0.80084678,\n",
              "       -0.74430825, -0.72418926, -0.69851088, -0.68745917, -0.58323568,\n",
              "       -0.54198028, -0.48910616, -0.45989081, -0.45129035, -0.44618573,\n",
              "       -0.41169144, -0.40796625, -0.31905995, -0.21571084, -0.20903954,\n",
              "       -0.16270405, -0.07236451,  0.00630423,  0.01905682,  0.04038624,\n",
              "        0.09572403,  0.12101566,  0.12479024,  0.15773001,  0.16386132,\n",
              "        0.18203006,  0.22235202,  0.22812499,  0.28492011,  0.29378029,\n",
              "        0.3593506 ,  0.36383185,  0.39512507,  0.50805498,  0.52952438,\n",
              "        0.59355294,  0.59742788,  0.69935019,  0.74849643,  0.7657048 ,\n",
              "        0.84568607,  0.86527145,  0.89744363,  0.95536742,  0.97183697])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI_sjYkiTDzw",
        "colab_type": "code",
        "outputId": "40c96a21-775c-4302-dcae-ce1f80163599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "f = 1\n",
        "y = np.sin(2*np.pi*f*X)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.58761094,  0.60432987,  0.76918717,  0.82052223,  0.94939894,\n",
              "        0.9993606 ,  0.98687865,  0.94812363,  0.92378133,  0.49946855,\n",
              "        0.26072189, -0.06839461, -0.24935432, -0.30129622, -0.33171888,\n",
              "       -0.52682347, -0.54657195, -0.90732613, -0.97688133, -0.96706475,\n",
              "       -0.85330936, -0.43917448,  0.03960026,  0.11945163,  0.25103971,\n",
              "        0.56584014,  0.68918508,  0.70617425,  0.83659994,  0.85707806,\n",
              "        0.91018423,  0.98494904,  0.99056933,  0.97602615,  0.96240355,\n",
              "        0.77310771,  0.75494465,  0.61228594, -0.0505893 , -0.18444501,\n",
              "       -0.55454032, -0.57463446, -0.94978692, -0.99995538, -0.99513546,\n",
              "       -0.82464994, -0.74898207, -0.60070342, -0.27677349, -0.17603148])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iro42no3tj_T",
        "colab_type": "text"
      },
      "source": [
        "However, in order to fit our functions, we must first colapse it such that the output Y is the sum of the polynomials of the input value X multiplied to the coefficients W.\n",
        "\n",
        "Therefore we setup a larger dataset using the following function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp-vnIHFuaVo",
        "colab_type": "code",
        "outputId": "66f8a364-f5b9-473f-ba59-9a6a2e4f3e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "features = pd.DataFrame('0': [],'1':[], '2':[],'3': [],'4':[])\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfFMkaoMVDqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_exp = 10\n",
        "for x_element in X:\n",
        "  k = 0\n",
        "  data = []\n",
        "  while k <= max_exp:\n",
        "    data.append(x_element**k)\n",
        "    k+=1\n",
        "  datapoints = list(data)\n",
        "  features.append(datapoints, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGxyovXEzboR",
        "colab_type": "code",
        "outputId": "728027db-562b-423f-cff2-e9f9b2fca369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-GvCbZT7z2",
        "colab_type": "text"
      },
      "source": [
        "Let's set up training data. Recall, data needs to be in $(features \\times \\text{number_of_examples})$ shape. So, we need to transpose X and Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt85gpSBayl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_entry = {'X0': [],'X': [],'X2':[], 'X3':[],'X4': [],'X5':[], 'Y' : []}\n",
        "features = pd.DataFrame(new_entry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1X8XYftZc1M",
        "colab_type": "text"
      },
      "source": [
        "Lets try it on a this simple dataset for curve fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6mkfmL8Zb28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "powers = 5\n",
        "ffs = []\n",
        "for i in X_train:\n",
        "  exponent = 0\n",
        "  feature_space = []\n",
        "  while exponent <= powers:\n",
        "    feature_space.append(i**exponent)\n",
        "    exponent+=1\n",
        "  ffs.append(feature_space)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71dabb22-a0a3-484e-9a18-f360aa45722a",
        "id": "C21n_1XMnX5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "fmat = features.as_matrix(columns = ('X0','X','X2','X3','X4','X5'))\n",
        "fmat.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ForKRYyPjWp1",
        "colab_type": "code",
        "outputId": "db68854e-d89f-48c5-db11-8605ccbcd09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "features['X0'] = ffs[0][0]\n",
        "features['X'] = ffs[0][1]\n",
        "features['X2'] = ffs[0][2]\n",
        "features['X3'] = ffs[0][3]\n",
        "features['X4'] = ffs[0][4]\n",
        "features['X5'] = ffs[0][5]\n",
        "features['Y'] = y\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X0</th>\n",
              "      <th>X</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.900034</td>\n",
              "      <td>0.810062</td>\n",
              "      <td>-0.729083</td>\n",
              "      <td>0.656200</td>\n",
              "      <td>-0.590602</td>\n",
              "      <td>0.587611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.896720</td>\n",
              "      <td>0.804108</td>\n",
              "      <td>-0.721060</td>\n",
              "      <td>0.646589</td>\n",
              "      <td>-0.579810</td>\n",
              "      <td>0.604330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.860331</td>\n",
              "      <td>0.740169</td>\n",
              "      <td>-0.636790</td>\n",
              "      <td>0.547850</td>\n",
              "      <td>-0.471332</td>\n",
              "      <td>0.769187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.846841</td>\n",
              "      <td>0.717140</td>\n",
              "      <td>-0.607304</td>\n",
              "      <td>0.514290</td>\n",
              "      <td>-0.435522</td>\n",
              "      <td>0.820522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.800847</td>\n",
              "      <td>0.641356</td>\n",
              "      <td>-0.513628</td>\n",
              "      <td>0.411337</td>\n",
              "      <td>-0.329418</td>\n",
              "      <td>0.949399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    X0         X        X2        X3        X4        X5         Y\n",
              "0  1.0 -0.900034  0.810062 -0.729083  0.656200 -0.590602  0.587611\n",
              "1  1.0 -0.896720  0.804108 -0.721060  0.646589 -0.579810  0.604330\n",
              "2  1.0 -0.860331  0.740169 -0.636790  0.547850 -0.471332  0.769187\n",
              "3  1.0 -0.846841  0.717140 -0.607304  0.514290 -0.435522  0.820522\n",
              "4  1.0 -0.800847  0.641356 -0.513628  0.411337 -0.329418  0.949399"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-UldcSlWND9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sigmoid(Z):\n",
        "    return 1/(1+np.exp(-Z))\n",
        "\n",
        "def Relu(Z):\n",
        "    return np.maximum(0,Z)\n",
        "\n",
        "def dRelu2(dZ, Z):    \n",
        "    dZ[Z <= 0] = 0    \n",
        "    return dZ\n",
        "\n",
        "def dRelu(x):\n",
        "    x[x<=0] = 0\n",
        "    x[x>0] = 1\n",
        "    return x\n",
        "\n",
        "def dSigmoid(Z):\n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = s * (1-s)\n",
        "    return dZ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI9O5R4ANnBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dlnet:\n",
        "    def __init__(self, x, y):\n",
        "        self.debug = 0;\n",
        "        self.X=x\n",
        "        self.Y=y\n",
        "        self.Yh=np.zeros((1,self.Y.shape[1])) \n",
        "        self.L=2\n",
        "        self.dims = [6, 15, 1] \n",
        "        self.param = {}\n",
        "        self.ch = {}\n",
        "        self.grad = {}\n",
        "        self.loss = []\n",
        "        self.lr=0.003\n",
        "        self.sam = self.Y.shape[1]\n",
        "        self.threshold=0.5\n",
        "        \n",
        "    def nInit(self):    \n",
        "        np.random.seed(1)\n",
        "        self.param['W1'] = np.random.randn(self.dims[1], self.dims[0]) / np.sqrt(self.dims[0]) \n",
        "        self.param['b1'] = np.zeros((self.dims[1], 1))        \n",
        "        self.param['W2'] = np.random.randn(self.dims[2], self.dims[1]) / np.sqrt(self.dims[1]) \n",
        "        self.param['b2'] = np.zeros((self.dims[2], 1))                \n",
        "        return \n",
        "\n",
        "    def forward(self):    \n",
        "        Z1 = self.param['W1'].dot(self.X) + self.param['b1'] \n",
        "        A1 = Relu(Z1)\n",
        "        self.ch['Z1'],self.ch['A1']=Z1,A1\n",
        "        \n",
        "        Z2 = self.param['W2'].dot(A1) + self.param['b2']  \n",
        "        A2 = Linear(Z2)\n",
        "        self.ch['Z2'],self.ch['A2']=Z2,A2\n",
        "\n",
        "        self.Yh=A2\n",
        "        loss=self.nloss(A2)\n",
        "        return self.Yh, loss\n",
        "\n",
        "    def nloss(self,Yh):\n",
        "        loss = (1./self.sam) * (-np.dot(self.Y,np.log(Yh).T) - np.dot(1-self.Y, np.log(1-Yh).T))    \n",
        "        return loss\n",
        "\n",
        "    def backward(self):\n",
        "        dLoss_Yh = - (np.divide(self.Y, self.Yh ) - np.divide(1 - self.Y, 1 - self.Yh))    \n",
        "        \n",
        "        dLoss_Z2 = dLoss_Yh * dSigmoid(self.ch['Z2'])    \n",
        "        dLoss_A1 = np.dot(self.param[\"W2\"].T,dLoss_Z2)\n",
        "        dLoss_W2 = 1./self.ch['A1'].shape[1] * np.dot(dLoss_Z2,self.ch['A1'].T)\n",
        "        dLoss_b2 = 1./self.ch['A1'].shape[1] * np.dot(dLoss_Z2, np.ones([dLoss_Z2.shape[1],1])) \n",
        "                            \n",
        "        dLoss_Z1 = dLoss_A1 * dRelu(self.ch['Z1'])        \n",
        "        dLoss_A0 = np.dot(self.param[\"W1\"].T,dLoss_Z1)\n",
        "        dLoss_W1 = 1./self.X.shape[1] * np.dot(dLoss_Z1,self.X.T)\n",
        "        dLoss_b1 = 1./self.X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n",
        "        \n",
        "        self.param[\"W1\"] = self.param[\"W1\"] - self.lr * dLoss_W1\n",
        "        self.param[\"b1\"] = self.param[\"b1\"] - self.lr * dLoss_b1\n",
        "        self.param[\"W2\"] = self.param[\"W2\"] - self.lr * dLoss_W2\n",
        "        self.param[\"b2\"] = self.param[\"b2\"] - self.lr * dLoss_b2\n",
        "        \n",
        "        return\n",
        "\n",
        "\n",
        "    def pred(self,x, y):  \n",
        "        self.X=x\n",
        "        self.Y=y\n",
        "        comp = np.zeros((1,x.shape[1]))\n",
        "        pred, loss= self.forward()    \n",
        "    \n",
        "        for i in range(0, pred.shape[1]):\n",
        "            if pred[0,i] > self.threshold: comp[0,i] = 1\n",
        "            else: comp[0,i] = 0\n",
        "    \n",
        "        print(\"Acc: \" + str(np.sum((comp == y)/x.shape[1])))\n",
        "        \n",
        "        return comp\n",
        "    \n",
        "    def gd(self,X, Y, iter = 3000):\n",
        "        np.random.seed(1)                         \n",
        "    \n",
        "        self.nInit()\n",
        "    \n",
        "        for i in range(0, iter):\n",
        "            Yh, loss=self.forward()\n",
        "            self.backward()\n",
        "        \n",
        "            if i % 500 == 0:\n",
        "                print (\"Cost after iteration %i: %f\" %(i, loss))\n",
        "                self.loss.append(loss)\n",
        "\n",
        "        plt.plot(np.squeeze(self.loss))\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Iter')\n",
        "        plt.title(\"Lr =\" + str(self.lr))\n",
        "        plt.show()\n",
        "    \n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLCDn56ToH7o",
        "colab_type": "code",
        "outputId": "7d46984f-3364-4d46-a059-87c0e3612067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2HKWUVjpGln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr = features.iloc[0:40, : 6].values.transpose()\n",
        "y_tr = np.expand_dims(features.iloc[0:40, 6],1).T\n",
        "#x_tr = np.expand_dims(x_tr, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFftWBxKpVs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xval = features.iloc[41:50, : 6].values.transpose()\n",
        "yval = np.expand_dims(features.iloc[41:50, 6],1).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xkmMnZ_piG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = dlnet(x_tr,y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n_E2zBVqJXJ",
        "colab_type": "code",
        "outputId": "42544d3f-fcd7-4b72-fb36-6feafcf714a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "yval.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_YVB3Y1qSuG",
        "colab_type": "code",
        "outputId": "2d135ed6-0e4b-4fc2-9de3-e45bff4cd815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nn.gd(x, y, iter = 67000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.784179\n",
            "Cost after iteration 500: 0.630888\n",
            "Cost after iteration 1000: 0.598518\n",
            "Cost after iteration 1500: 0.576412\n",
            "Cost after iteration 2000: 0.555036\n",
            "Cost after iteration 2500: 0.534417\n",
            "Cost after iteration 3000: 0.514120\n",
            "Cost after iteration 3500: 0.493970\n",
            "Cost after iteration 4000: 0.473722\n",
            "Cost after iteration 4500: 0.453316\n",
            "Cost after iteration 5000: 0.432748\n",
            "Cost after iteration 5500: 0.412022\n",
            "Cost after iteration 6000: 0.391256\n",
            "Cost after iteration 6500: 0.370632\n",
            "Cost after iteration 7000: 0.350327\n",
            "Cost after iteration 7500: 0.330472\n",
            "Cost after iteration 8000: 0.311009\n",
            "Cost after iteration 8500: 0.291911\n",
            "Cost after iteration 9000: 0.273163\n",
            "Cost after iteration 9500: 0.255471\n",
            "Cost after iteration 10000: 0.238164\n",
            "Cost after iteration 10500: 0.221067\n",
            "Cost after iteration 11000: 0.203991\n",
            "Cost after iteration 11500: 0.186844\n",
            "Cost after iteration 12000: 0.169565\n",
            "Cost after iteration 12500: 0.153300\n",
            "Cost after iteration 13000: 0.137182\n",
            "Cost after iteration 13500: 0.121130\n",
            "Cost after iteration 14000: 0.104986\n",
            "Cost after iteration 14500: 0.088556\n",
            "Cost after iteration 15000: 0.071799\n",
            "Cost after iteration 15500: 0.054567\n",
            "Cost after iteration 16000: 0.037016\n",
            "Cost after iteration 16500: 0.019206\n",
            "Cost after iteration 17000: 0.000952\n",
            "Cost after iteration 17500: -0.017826\n",
            "Cost after iteration 18000: -0.037204\n",
            "Cost after iteration 18500: -0.057253\n",
            "Cost after iteration 19000: -0.078059\n",
            "Cost after iteration 19500: -0.099692\n",
            "Cost after iteration 20000: -0.122228\n",
            "Cost after iteration 20500: -0.145751\n",
            "Cost after iteration 21000: -0.170306\n",
            "Cost after iteration 21500: -0.195974\n",
            "Cost after iteration 22000: -0.222833\n",
            "Cost after iteration 22500: -0.251007\n",
            "Cost after iteration 23000: -0.280618\n",
            "Cost after iteration 23500: -0.311777\n",
            "Cost after iteration 24000: -0.344596\n",
            "Cost after iteration 24500: -0.379182\n",
            "Cost after iteration 25000: -0.415647\n",
            "Cost after iteration 25500: -0.454108\n",
            "Cost after iteration 26000: -0.494683\n",
            "Cost after iteration 26500: -0.537504\n",
            "Cost after iteration 27000: -0.582701\n",
            "Cost after iteration 27500: -0.630415\n",
            "Cost after iteration 28000: -0.680783\n",
            "Cost after iteration 28500: -0.733959\n",
            "Cost after iteration 29000: -0.790092\n",
            "Cost after iteration 29500: -0.849352\n",
            "Cost after iteration 30000: -0.911915\n",
            "Cost after iteration 30500: -0.977927\n",
            "Cost after iteration 31000: -1.047630\n",
            "Cost after iteration 31500: -1.121165\n",
            "Cost after iteration 32000: -1.198753\n",
            "Cost after iteration 32500: -1.280938\n",
            "Cost after iteration 33000: -1.367596\n",
            "Cost after iteration 33500: -1.459261\n",
            "Cost after iteration 34000: -1.555777\n",
            "Cost after iteration 34500: -1.658570\n",
            "Cost after iteration 35000: -1.787187\n",
            "Cost after iteration 35500: -1.909439\n",
            "Cost after iteration 36000: -2.034332\n",
            "Cost after iteration 36500: -2.166104\n",
            "Cost after iteration 37000: -2.305126\n",
            "Cost after iteration 37500: -2.508555\n",
            "Cost after iteration 38000: -2.693855\n",
            "Cost after iteration 38500: -2.870237\n",
            "Cost after iteration 39000: -3.056444\n",
            "Cost after iteration 39500: -3.253059\n",
            "Cost after iteration 40000: -3.460866\n",
            "Cost after iteration 40500: -3.680648\n",
            "Cost after iteration 41000: -3.913119\n",
            "Cost after iteration 41500: -4.159007\n",
            "Cost after iteration 42000: -4.419223\n",
            "Cost after iteration 42500: -4.694540\n",
            "Cost after iteration 43000: -4.986018\n",
            "Cost after iteration 43500: -5.294618\n",
            "Cost after iteration 44000: -5.621371\n",
            "Cost after iteration 44500: -5.967301\n",
            "Cost after iteration 45000: -6.333879\n",
            "Cost after iteration 45500: -6.722111\n",
            "Cost after iteration 46000: -7.133515\n",
            "Cost after iteration 46500: -7.569432\n",
            "Cost after iteration 47000: -8.031248\n",
            "Cost after iteration 47500: -8.520707\n",
            "Cost after iteration 48000: -9.039498\n",
            "Cost after iteration 48500: -9.589365\n",
            "Cost after iteration 49000: -10.172163\n",
            "Cost after iteration 49500: -10.790088\n",
            "Cost after iteration 50000: -11.445104\n",
            "Cost after iteration 50500: -12.139242\n",
            "Cost after iteration 51000: -12.875657\n",
            "Cost after iteration 51500: -13.656373\n",
            "Cost after iteration 52000: -14.483956\n",
            "Cost after iteration 52500: -15.361178\n",
            "Cost after iteration 53000: -16.291423\n",
            "Cost after iteration 53500: -17.277838\n",
            "Cost after iteration 54000: -18.323561\n",
            "Cost after iteration 54500: -19.432220\n",
            "Cost after iteration 55000: -20.624403\n",
            "Cost after iteration 55500: -21.914935\n",
            "Cost after iteration 56000: -23.245676\n",
            "Cost after iteration 56500: -24.654751\n",
            "Cost after iteration 57000: -26.148353\n",
            "Cost after iteration 57500: -27.732140\n",
            "Cost after iteration 58000: -29.412452\n",
            "Cost after iteration 58500: -31.193633\n",
            "Cost after iteration 59000: -33.082833\n",
            "Cost after iteration 59500: -35.087163\n",
            "Cost after iteration 60000: -37.209972\n",
            "Cost after iteration 60500: nan\n",
            "Cost after iteration 61000: nan\n",
            "Cost after iteration 61500: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in less_equal\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 62000: nan\n",
            "Cost after iteration 62500: nan\n",
            "Cost after iteration 63000: nan\n",
            "Cost after iteration 63500: nan\n",
            "Cost after iteration 64000: nan\n",
            "Cost after iteration 64500: nan\n",
            "Cost after iteration 65000: nan\n",
            "Cost after iteration 65500: nan\n",
            "Cost after iteration 66000: nan\n",
            "Cost after iteration 66500: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_6g_x6srhzQ",
        "colab_type": "code",
        "outputId": "231396a9-0ab8-48ff-ce72-25e541631042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "pred_train = nn.pred(x_tr, y_tr)\n",
        "pred_test = nn.pred(xval, yval)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.0\n",
            "Acc: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsZUIdvHr_xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}